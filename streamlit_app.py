import streamlit as st
from transformers import AutoModelForCausalLM, AutoTokenizer
from sentence_transformers import SentenceTransformer, util
import torch
import json
import requests

# âœ… ëª¨ë¸ ë¡œë”©
@st.cache_resource
def load_models():
    adapter_model_id = "JungWook0116/ko-mistral7b-v1-book-recommender"
    base = AutoModelForCausalLM.from_pretrained(
        adapter_model_id, torch_dtype=torch.float16, device_map="auto", use_safetensors=True
    )
    tokenizer = AutoTokenizer.from_pretrained(adapter_model_id)
    sbert = SentenceTransformer("intfloat/multilingual-e5-base")
    return base, tokenizer, sbert

# âœ… ë„ì„œ ë°ì´í„° ë¡œë”©
@st.cache_data
def load_books():
    url = "https://raw.githubusercontent.com/jungwook-student/hf_transformers_model/main/aladin_fully_enriched_upto_now_552.json"
    data = requests.get(url).json()
    return [book for book in data if "theme" in book and "type" in book and "age" in book]

# âœ… ì¡°ê±´ ì¶”ì¶œ í•¨ìˆ˜
def extract_conditions(prompt, model, tokenizer):
    input_text = f"### Instruction:\në‹¤ìŒ ë¬¸ì¥ì„ ë¶„ì„í•˜ì—¬ ë„ì„œ ì¶”ì²œ ì¡°ê±´ì„ ì¶”ì¶œí•˜ì„¸ìš”.\n\n### Input:\n{prompt}\n\n### Output:\n"
    input_ids = tokenizer(input_text, return_tensors="pt").input_ids.to(model.device)
    with torch.no_grad():
        output = model.generate(input_ids, max_new_tokens=50)
    decoded = tokenizer.decode(output[0], skip_special_tokens=True)
    extracted = decoded.split("### Output:")[-1].strip()
    return extracted

# âœ… ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œ
def recommend_books(prompt, model, tokenizer, sbert, books, top_k=5):
    extracted = extract_conditions(prompt, model, tokenizer)
    st.markdown(f"ğŸ¯ **ì¶”ì¶œëœ ì¡°ê±´**: `{extracted}`")

    # í•„í„°ë§ ë° ìœ ì‚¬ë„ ê¸°ë°˜ ìŠ¤ì½”ì–´ë§
    candidates = []
    for book in books:
        if "theme" not in book or "types" not in book or "age" not in book:
            continue
        theme_score = max([difflib.SequenceMatcher(None, t, bt).ratio()
                          for t in extracted["theme"] for bt in book["theme"]]) if extracted["theme"] else 0.0
        type_score = max([difflib.SequenceMatcher(None, extracted["type"], bt).ratio()
                         for bt in book["types"]]) if extracted["type"] else 0.0
        import re
        try:
            user_age = int(re.findall(r'\d+', extracted["age"])[0])
            book_ages = [int(x) for x in re.findall(r'\d+', book["age"])]
            age_score = 1.0 if user_age in book_ages else 0.0
        except:
            age_score = 0.0
        final_score = (theme_score + type_score + age_score) / 3
        if final_score > 0:
            candidates.append((final_score, book))

    candidates.sort(reverse=True, key=lambda x: x[0])
    filtered_books = [b for _, b in candidates]
    st.markdown(f"âœ… **ìŠ¤ì½”ì–´ë§ëœ ë„ì„œ ìˆ˜**: {len(filtered_books)}")

    if not filtered_books:
        st.warning("âŒ ì¶”ì²œí•  ë„ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    candidate_texts = [
        f"query: theme={' '.join(t for theme in b['theme'] for t in (theme if isinstance(theme, list) else [theme]))}, type={' '.join(b['types'])}, age={b['age']}"
        for b in filtered_books
    ]
    query = f"query: theme={' '.join(extracted['theme'])}, type={extracted['type']}, age={extracted['age']}"
    query_vec = sbert.encode([query], convert_to_tensor=True)
    corpus_embs = sbert.encode(candidate_texts, convert_to_tensor=True).to(query_vec.device)
    scores = util.cos_sim(query_vec, corpus_embs)[0]
    top_k_indices = torch.topk(scores, k=min(top_k, len(filtered_books))).indices.tolist()

    st.markdown("ğŸ” **ì¶”ì²œ ë„ì„œ ê²°ê³¼:**")
    for idx in top_k_indices:
        b = filtered_books[idx]
        st.write(f"- **{b['title']}** ({b['age']}, {b['types']})")

# âœ… Streamlit UI êµ¬ì„±
st.title("ğŸ“š ìœ ì•„ ë„ì„œ ì¶”ì²œê¸°")

with st.spinner("ì´ˆê¸° ë¡œë”© ì¤‘ì…ë‹ˆë‹¤. ëª¨ë¸ê³¼ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ìˆìŠµë‹ˆë‹¤..."):
    model, tokenizer, sbert = load_models()
    books = load_books()

st.success("âœ… ì´ˆê¸°í™” ì™„ë£Œ! ì´ì œ ë¬¸ì¥ì„ ì…ë ¥í•´ë³´ì„¸ìš”.")
user_input = st.text_input("ì¶”ì²œì„ ìœ„í•œ ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”:")

if user_input:
    with st.spinner("ì¶”ì²œ ì¤‘..."):
        recommend_books(user_input, model, tokenizer, sbert, books)
